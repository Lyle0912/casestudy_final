---
title: "Case study Project 1"
author: "Ly Le Thi"
date: "2023-10-27"
output: pdf
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load library


```{r}
rm(list = ls())
```

```{r, warning=FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
library(dplyr) 
library(ggplot2)
library(zoo)
library(here)
library(readxl)
library(dplyr)
library(magrittr)
library(ggplot2)
library(gridExtra)
library(mice)
library(quantmod)
library(tsibble)
library(stats)
library(purrr)
library(rlang)
library(forecast)
library(lmSubsets)
```

## a. Import dataset

```{r}
tsdata <- read_excel("~/Desktop/case study/PredictorData2022.xlsx")
ts_quarter <- read_excel("~/Desktop/case study/PredictorData2022.xlsx", sheet = "Quarterly")
ts_year <- read_excel("~/Desktop/case study/PredictorData2022.xlsx", sheet = "Annual")


tsdata$yyyymm <- as.yearmon(as.character(tsdata$yyyymm), format="%Y%m")
ts_quarter$yyyyq <- as.yearqtr(as.character(ts_quarter$yyyyq), format="%Y%q")
ts_year$yyyy <- as.Date(as.character(ts_year$yyyy), format="%Y")

tsdata %<>% select(-CRSP_SPvw, -CRSP_SPvwx, -csp)
ts_quarter %<>% select(-CRSP_SPvw, -CRSP_SPvwx, -csp)
ts_year %<>% select(-CRSP_SPvw, -CRSP_SPvwx, -csp)
```

```{r}
vars_monthly <- names(tsdata)
vars_quarterly <-names(ts_quarter) 
vars_annual <-names(ts_year)

setdiff(vars_quarterly,vars_monthly)
setdiff(vars_annual,vars_monthly)
```

```{r}
# Rename the column
colname_mapping <- c(
"time" = "yyyymm",
  "time" = "yyyyq",
  "time" = "yyyy",
  "sp_index" = "Index",
  "dividend_12" = "D12",
  "earning_12" = "E12",
  "bookmarketRatio" = "b/m",
  "treasury_bill" = "tbl",
  "cor_AAA" = "AAA",
  "cor_BAA" = "BAA",
  "longterm_yeild" = "lty",
  "net_equity" = "ntis",
  "risk_free" = "Rfree",
  "inflation" = "infl",
  "long_returnrate" = "ltr",
  "cbond_return" = "corpr",
  "stock_var" = "svar",
  "cs_premium" = "csp",
  "consumWealIncome" = "cay",
  "investmentCapital" = "ik",
  "dividend3year" = "D3",
  "earning3year" = "E3",
  "consum_wealth_monthly" = "caym",
  "equity_issuing" = "eqis"
)

#Rename columns 
filtered_dict_monthly <- colname_mapping[colname_mapping %in% colnames(tsdata)]
tsdata <- rename(tsdata, !!!filtered_dict_monthly)

filtered_dict_quarterly <- colname_mapping[colname_mapping %in% colnames(ts_quarter)]
ts_quarter <- rename(ts_quarter, !!!filtered_dict_quarterly)

filtered_dict_annual <- colname_mapping[colname_mapping %in% colnames(ts_year)]
ts_year <- rename(ts_year, !!!filtered_dict_annual)

# Transform variables into numeric
for(i in names(tsdata)) {
  if(class(tsdata[[i]]) == "character") {
    tsdata[[i]] <- as.numeric(tsdata[[i]])
  }
}

for(i in names(ts_quarter)) {
  if(class(ts_quarter[[i]]) == "character") {
    ts_quarter[[i]] <- as.numeric(ts_quarter[[i]])
  }
}

for(i in names(ts_year)) {
  if(class(ts_year[[i]]) == "character") {
    ts_year[[i]] <- as.numeric(ts_year[[i]])
  }
}

## Generate the excess returns series

calculate_returns <- function(input){
  input %<>% mutate(returns = as.vector(quantmod::Delt(sp_index))) 
  input %<>% mutate(excess_returns = returns - risk_free)
  return(input)
}

tsdata %<>% calculate_returns()
ts_quarter %<>% calculate_returns()
ts_year %<>% calculate_returns()

# Taking lag of all predictors

lag_predictors <- function(input){
  output <- input %>%
    mutate(across(-c(time, excess_returns), lag, .names = "lag_{.col}")) %>% 
    select(time, excess_returns, starts_with("lag_")) %>% 
    slice(-1) 
  return(output)
}
tsdata %<>% lag_predictors()
ts_quarter %<>% lag_predictors()
ts_year %<>% lag_predictors()

## Drop the value that not much important and almost or more than 50% NA
ts_quarter %<>% select(-lag_consumWealIncome, -lag_investmentCapital, -lag_dividend3year, -lag_earning3year)
ts_year %<>% select(-lag_consumWealIncome, -lag_investmentCapital)
```


```{r}
excessmonth <- tsdata%>% dplyr::select(c("time", "excess_returns"))
excessquarter <- ts_quarter%>% dplyr::select(c("time", "excess_returns"))
excessyear <- ts_year%>% dplyr::select(c("time", "excess_returns"))
# Taking the lag
for (i in 1:10) {
  excessmonth <- mutate(excessmonth, !!paste("er_lag_", i, sep = "") := lag(excess_returns, i))
}

for (i in 1:10) {
  excessquarter <- mutate(excessquarter, !!paste("er_lag_", i, sep = "") := lag(excess_returns, i))
}

for (i in 1:10) {
  excessyear <- mutate(excessyear, !!paste("er_lag_", i, sep = "") := lag(excess_returns, i))
}
#plug back to tsdata

tsdata <- merge(tsdata, excessmonth, by = "time", all.x = TRUE) 
tsdata <- tsdata[, -grep("excess_returns.y", colnames(tsdata))]

ts_quarter <- merge(ts_quarter, excessquarter, by = "time", all.x = TRUE) 
ts_quarter <- ts_quarter[, -grep("excess_returns.y", colnames(ts_quarter))]

ts_year <- merge(ts_year, excessyear, by = "time", all.x = TRUE) 
ts_year <- ts_year[, -grep("excess_returns.y", colnames(ts_year))]

```


```{r}
tsdata <- na.omit(tsdata)
ts_quarter <- na.omit(ts_quarter)
ts_year <- na.omit(ts_year)
```


#### Cut the dataset

```{r}
tsdata$time <- as.Date(tsdata$time)
num_points_to_cut <- 120

# Identify the cutoff index
cutoff_index <- nrow(tsdata) - num_points_to_cut

# Training set remains the same
tsdata <- tsdata[1:cutoff_index, ]

# Testing set
testing_data <- tsdata[cutoff_index:nrow(tsdata), ]
tail(tsdata)
```

```{r}
ts_quarter$time <- as.Date(ts_quarter$time)
num_points_to_cut <- 40

# Identify the cutoff index
cutoff_index <- nrow(ts_quarter) - num_points_to_cut 

# Training set remains the same
ts_quarter <- ts_quarter[1:cutoff_index, ]

# Testing set
testing_data <- ts_quarter[cutoff_index:nrow(ts_quarter), ]
tail(ts_quarter)
```



```{r}
ts_year$time <- as.Date(ts_year$time)
num_points_to_cut <- 10

# Identify the cutoff index
cutoff_index <- nrow(ts_year) - num_points_to_cut

# Training set remains the same
ts_year <- ts_year[1:cutoff_index, ]

# Testing set
testing_data <- ts_year[cutoff_index:nrow(ts_year), ]
tail(ts_year)
```



```{r}
excessmonth$time <- as.Date(excessmonth$time)
num_points_to_cut <- 120

# Identify the cutoff index
cutoff_index <- nrow(excessmonth) - num_points_to_cut

# Training set remains the same
excessmonth <- excessmonth[1:cutoff_index, ]

# Testing set
testing_data <- excessmonth[cutoff_index:nrow(excessmonth), ]
```


```{r}
#quarter

excessquarter$time <- as.Date(excessquarter$time)
num_points_to_cut <- 40

# Identify the cutoff index
cutoff_index <- nrow(excessquarter) - num_points_to_cut

# Training set remains the same
excessquarter <- excessquarter[1:cutoff_index, ]

# Testing set
testing_data <- excessquarter[cutoff_index:nrow(excessquarter), ]




#### annual

excessyear$time <- as.Date(excessyear$time)
num_points_to_cut <- 10

# Identify the cutoff index
cutoff_index <- nrow(excessyear) - num_points_to_cut

# Training set remains the same
excessyear <- excessyear[1:cutoff_index, ]

# Testing set
testing_data <- excessyear[cutoff_index:nrow(excessyear), ]
```



## c. Structure of excess return series

# Plot excess return series

```{r, warning=FALSE}
excess_returns_plot <- ggplot(tsdata, aes(x = time, y = excess_returns.x)) +
  geom_line() +
  labs(title = "Time Series Plot of Monthly Excess Returns", x = "Time", y = "Excess Return")+
  theme_bw()
print(excess_returns_plot)
```

```{r, warning=FALSE}
excess_returns_plotq <- ggplot(ts_quarter, aes(x = time, y = excess_returns.x)) +
  geom_line() +
  labs(title = "Time Series Plot of Quaterly Excess Returns", x = "Time", y = "Excess Return")+
  theme_bw()

print(excess_returns_plotq)
```

```{r, warning=FALSE}
excess_returns_ploty <- ggplot(ts_year, aes(x = time, y = excess_returns.x)) +
  geom_line() +
  labs(title = "Time Series Plot of Yearly Excess Returns", x = "Time", y = "Excess Return")+
  theme_bw()

print(excess_returns_ploty)

```

```{r}
summary(tsdata$excess_returns.x)
summary(ts_quarter$excess_returns.x)
summary(ts_year$excess_returns.x)
tsdata$excess_returns.x %>% var(na.rm=TRUE)
ts_quarter$excess_returns.x %>% var(na.rm=TRUE)
ts_year$excess_returns.x %>% var(na.rm=TRUE)
```

## Plot acf and pacf
# Monthly

```{r}
excess_rt <- na.omit(tsdata$excess_returns.x)
```

```{r}
acf_result <- Acf(excess_rt, lag.max = 60, main = "ACF of Excess Return Monthly")
```

```{r}
pacf_result <- pacf(excess_rt,lag.max = 60, main = "PACF of Excess Return Mothly")
```
Look more likely AR(1) model

# Quaterly

```{r}
excess_rtq <- na.omit(ts_quarter$excess_returns.x)
```

```{r}
acf_resultq <- Acf(excess_rtq, lag.max = 60, main = "ACF of Excess Return Quarterly")
```

```{r}
pacf_resultq <- pacf(excess_rtq,lag.max = 60, main = "PACF of Excess Return Quarterly")
```
Look like AR(3, AR(4) 

# Yearly

```{r}
excess_rty <- na.omit(ts_year$excess_returns.x)
```

```{r}
acf_resulty <- Acf(excess_rty, main = "ACF of Excess Return Annual")
```

```{r}
pacf_resulty <- pacf(excess_rty, main = "PACF of Excess Return Annual")
```
Look like no correlation. possibly can fit AR(2)

## d.e. Fit an AR models base on Information criteria and generate forecast




# For monthly data

```{r}
ar_modelling <- function(input) {
  data_cleaned <- input %>% filter(!is.na(excess_returns.x))
  
  p_values <- 1:3
  aic_values <- numeric(length(p_values))
  ar_models <- list()
  
  for (p in p_values) {
    AR_model <- arima(data_cleaned$excess_returns.x, order = c(p, 0, 0), method = "ML")
    
    aic_values[p] <- AIC(AR_model)
    
    ar_models[[p]] <- AR_model
  }
  
  best_p <- p_values[which.min(aic_values)]
  best_AR <- ar_models[[best_p]]
  
  # Calculate fitted values
  fitted_values <- data_cleaned$excess_returns - best_AR$residuals
  
  plot_data <- data.frame(
    Date = as.Date(input$time[!is.na(input$excess_returns)]),
    ExcessReturns = data_cleaned$excess_returns,
    Fitted = fitted_values
  )
  
  MSFE <- sqrt(mean(best_AR$residuals^2))
  
  # Plot data
  plot <- ggplot(plot_data, aes(x = Date)) +
    geom_line(aes(y = ExcessReturns), color = "black") +
    geom_line(aes(y = Fitted), color = "red") +
    labs(title = paste("Time Series with AR(", best_p, ") Fitted Values")) +
    theme_bw()
  
  result <- list(best_p = best_p, aic_values = aic_values, AR_model = best_AR, MSFE = MSFE, plot = plot)
  
  return(result)
}

```

```{r, warning=FALSE}
result <- ar_modelling(input = tsdata)
print(paste("Best AR(p) order:", result$best_p))
summary(result$AR_model)
print(paste("AIC values for p =", 1:3, ":", result$aic_values))
print(paste("MSFE:", result$MSFE))
print(result$plot)
```

```{r}
ar_modelling <- function(input) {
  data_cleaned <- input %>% filter(!is.na(excess_returns.x))
  
  p_values <- 1:5
  aic_values <- numeric(length(p_values))
  ar_models <- list()
  
  for (p in p_values) {
    AR_model <- arima(data_cleaned$excess_returns.x, order = c(p, 0, 0), method = "ML")
    
    aic_values[p] <- AIC(AR_model)
    
    ar_models[[p]] <- AR_model
  }
  
  best_p <- p_values[which.min(aic_values)]
  best_AR <- ar_models[[best_p]]
  
  # Calculate fitted values
  fitted_values <- data_cleaned$excess_returns.x - best_AR$residuals
  
  plot_data <- data.frame(
    Date = as.Date(input$time[!is.na(input$excess_returns.x)]),
    ExcessReturns = data_cleaned$excess_returns.x,
    Fitted = fitted_values
  )
  
  MSFE <- sqrt(mean(best_AR$residuals^2))
  
  # Plot data
  plot <- ggplot(plot_data, aes(x = Date)) +
    geom_line(aes(y = ExcessReturns), color = "black") +
    geom_line(aes(y = Fitted), color = "red") +
    labs(title = paste("Time Series with AR(", best_p, ") Fitted Values")) +
    theme_bw()
  
  result <- list(best_p = best_p, aic_values = aic_values, AR_model = best_AR, MSFE = MSFE, plot = plot)
  
  return(result)
}
```



```{r}
result <- ar_modelling(input = ts_quarter)
print(paste("Best AR(p) order:", result$best_p))
print(paste("AIC values for p =", 1:5, ":", result$aic_values))
summary(result$AR_model)
print(paste("MSFE:", result$MSFE))
print(result$plot)
```


```{r}
result <- ar_modelling(input = ts_year)
print(paste("Best AR(p) order:", result$best_p))
print(paste("AIC values for p =", 1:5, ":", result$aic_values))
summary(result$AR_model)
print(paste("MSFE:", result$MSFE))
print(result$plot)
```

## i. Forward stepwise model selection


```{r}
get_time_span <- function(data_input, model_input){
  coefficients_names <- model_input %>% coef() %>% names() %>% setdiff("(Intercept)")
  complete_cases <- which(complete.cases(data_input[c("excess_returns.x", coefficients_names)]))
  used_rows <- row.names(model_input$model)
  removed_rows <- setdiff(complete_cases, as.numeric(used_rows))
  included_time_spans <- data_input$time[as.numeric(used_rows)]
  output <- paste(included_time_spans %>% min() %>% year() %>% as.character(), "-", included_time_spans %>% max() %>% year() %>% as.character())
  return(output)
}
```


```{r}
stepwise_function <- function(input){
  input_name <- deparse(substitute(input))
  
  model <- step(object= lm(excess_returns.x ~ 1, data = input %>% na.omit()) 
                , scope = paste("excess_returns.x ~", paste(c(names(input %>% select(-excess_returns.x, -time))), collapse=" + ")) %>% as.formula()
                , direction = "forward", trace = FALSE, k=2) 
  
  output <- data.frame(
    Data = get_time_span(data_input=input, model_input=model),
    MSFE = mean(model$residuals^2)^0.5 ,
    R2 = summary(model)$r.squared
  )
  
  
  print(summary(model))
  return(output)
}
```



```{r}
stepwise_monthly <- stepwise_function(input=tsdata)
stepwise_quarterly <- stepwise_function(input=ts_quarter)
stepwise_annual <- stepwise_function(input=ts_year)
colnames(stepwise_monthly) <- c("Monthly","MSFE_monthly", "R2_monthly")
colnames(stepwise_quarterly) <- c("Quarterly","MSFE_quarterly", "R2_quarterly")
colnames(stepwise_annual) <- c("Annual","MSFE_annual", "R2_annual")
stepwise_complete <- cbind(stepwise_monthly, stepwise_quarterly, stepwise_annual)
rownames(stepwise_complete) <- c("stepwise LM")

```

```{r}
stepwise_complete
```

##### Model for Machine learning



```{r, warning=FALSE}

library(tidyverse)
library(lubridate)
library(readxl)
library(dplyr) 
library(ggplot2)
library(zoo)
library(here)
library(readxl)
library(dplyr)
library(magrittr)
library(ggplot2)
library(mice)
library(quantmod)
library(tsibble)
library(stats)
library(purrr)
library(rlang)
library(forecast)
library(lmSubsets)
library(caret)
library(rpart)
library(randomForest)
library(keras)
library(neuralnet)
library(DALEX)
library(tensorflow)

```



### ML for monthly

```{r}
# Traing and testing set
split_point <- round(0.8 * nrow(excessmonth))

# Create training and testing sets based on the split point
train_data_er <- subset(excessmonth, time <= excessmonth$time[split_point])
test_data_er <- subset(excessmonth, time > excessmonth$time[split_point])
# Define the formula
max_lag <- 10
formula_er <- as.formula(paste("excess_returns ~", paste(paste("er_lag_", 1:max_lag, sep = ""), collapse = " + ")))
```



# Regression tree

```{r, warning=FALSE}
set.seed(128)

rt_model <- rpart(formula_er, data = train_data_er,control = rpart.control(cp = 0.01))

# Predictions
rt_predictions <- predict(rt_model, newdata = test_data_er)

# Add the predictions to excessmonth based on time
excessmonth$predicted_excess_returns_rt <- NA  
# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_er)) {
  time_index <- which(excessmonth$time == test_data_er$time[i])
  if (length(time_index) > 0) {
    excessmonth[time_index, "predicted_excess_returns_rt"] <- rt_predictions[i]
    
  }
}
    # Plot results
ggplot(excessmonth, aes(x = time)) +
  geom_line(aes(y = excess_returns, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rt, color = "Predicted")) +
  labs(title = "Actual vs. Predicted Excess Returns using Regression Tree",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))

# Calculate MSFE

rt_actual_values <- test_data_er$excess_returns
rt_rmse <- sqrt(mean((rt_predictions - rt_actual_values)^2))

cat("Mean Squared Forecast Error (MSFE):", rt_rmse, "\n")
```


```{r}

# Calculate and plot important using DALEX
train_data_er_subset <- train_data_er[, !names(train_data_er) %in% c("excess_returns", "time")]
explainer <- explain(model = rt_model,
                     data = train_data_er_subset,
                     y = train_data_er$excess_returns,
                     label = "Regression Tree Model")

# Calculate permutation feature importance
perm_importance <- variable_importance(explainer)

print(perm_importance)
model_explanations <- DALEX::model_parts(explainer)
plot(model_explanations)

```


## Random forest

```{r}
train_data_er <- na.omit(train_data_er)
test_data_er <- na.omit(test_data_er)
```


```{r, warning=FALSE}
set.seed(512)

rf_model <- randomForest(
  formula_er, 
  data = train_data_er,
  ntree = 162, 
  mtry = 3,  
  importance = TRUE 
)


rf_predictions <- predict(rf_model, newdata = test_data_er)

excessmonth$predicted_excess_returns_rf <- NA

# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_er)) {
  time_index <- which(excessmonth$time == test_data_er$time[i])
  if (length(time_index) > 0) {
    excessmonth[time_index, "predicted_excess_returns_rf"] <- rf_predictions[i]
  }
}
# Plot results
ggplot(excessmonth, aes(x = time)) +
  geom_line(aes(y = excess_returns, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rf, color = "Predicted"), linetype = "dashed") +
  labs(title = "Actual vs. Predicted Excess Returns using Random Forest",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))

rf_actual_values <- test_data_er$excess_returns
rf_msfe <- sqrt(mean((rf_predictions - rf_actual_values)^2))
cat("Mean Squared Forecast Error (MSFE):", rf_msfe, "\n")

```


```{r}

explainer2 <- explain(model = rf_model,
                      data = train_data_er_subset,
                      y = train_data_er$excess_returns,
                      label = "Random Forest Model")

# Calculate permutation feature importance
perm_importance2 <- variable_importance(explainer2)

print(perm_importance2)

# Generate model explanations
model_explanations2 <- DALEX::model_parts(explainer2)
plot(model_explanations2)

```


## Forecasting for the whole data

```{r}
tail(train_data_ts)
```


```{r}
# # Drop columns using subset
# tsdata <- subset(tsdata, select = -c(predicted_excess_returns_rt, predicted_excess_returns_rf))

# Traing and testing set
split_point <- round(0.8 * nrow(tsdata))

# Create training and testing sets based on the split point
train_data_ts <- subset(tsdata, time <= tsdata$time[split_point])
test_data_ts <- subset(tsdata, time > tsdata$time[split_point])
target_variable <- "excess_returns.x"

predictor_variables <- setdiff(names(tsdata), c(target_variable, "lag_returns", "time", "lag_sp_index"))

formula_all <- as.formula(paste(target_variable, "~", paste(paste(predictor_variables, collapse = " + "), collapse = " + "))) 
```

## Regression tree

```{r, warning=FALSE}
set.seed(1024)


rt_model_all <- rpart(formula_all, data = train_data_ts, control = rpart.control(cp = 0.009))

# Predictions using the general data regression tree model
rt_predictions_all <- predict(rt_model_all, newdata = test_data_ts)


tsdata$predicted_excess_returns_rt <- NA

# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_ts)) {
  time_index <- which(tsdata$time == test_data_ts$time[i])
  if (length(time_index) > 0) {
    tsdata[time_index, "predicted_excess_returns_rt"] <- rt_predictions_all[i]
  }
}

ggplot(tsdata, aes(x = time)) +
  geom_line(aes(y = excess_returns.x, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rt, color = "Predicted")) +
  labs(title = "Actual vs. Predicted Excess Returns using Regression Tree all",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))



# calculate MSFE

rt_actual_values_all <- test_data_ts$excess_returns.x
rt_msfe_all <- sqrt(mean((rt_predictions_all - rt_actual_values_all)^2))

cat("Mean Squared Forecast Error (MSFE) for Regression Tree:", rt_msfe_all, "\n")
```



```{r}

# Calculate feature importance
train_data_ts_subset <- train_data_ts[, !names(train_data_ts) %in% c("excess_returns.x", "time", "lag_returns","lag_sp_index")]

# Create an explainer object
explainer <- explain(model = rt_model_all,
                     data = train_data_ts_subset,
                     y = train_data_ts$excess_returns.x,
                     label = "Regression Tree Model")

# Calculate permutation feature importance
perm_importance <- variable_importance(explainer)
print(perm_importance)

# Generate model explanations
model_explanations <- DALEX::model_parts(explainer)
plot(model_explanations)

```


## Random Forest



```{r, warning=FALSE}
set.seed(512)

# Building the Random Forest model for general data
rf_model_all <- randomForest(
  formula_all,
  data = train_data_ts,
  ntree = 320,  
  mtry = 2,  
  importance = TRUE  
)


predictions_rf_all <- predict(rf_model_all, newdata = test_data_ts)

tsdata$predicted_excess_returns_rf <- NA

# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_ts)) {
  time_index <- which(tsdata$time == test_data_ts$time[i])
  if (length(time_index) > 0) {
    tsdata[time_index, "predicted_excess_returns_rf"] <- predictions_rf_all[i]
  }
}

ggplot(tsdata, aes(x = time)) +
  geom_line(aes(y = excess_returns.x, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rf, color = "Predicted"), linetype = "dashed") +
  labs(title = "Actual vs. Predicted Excess Returns using Random Forest all",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))

# Actual values from the test set for general data
rf_actual_values_all <- test_data_ts$excess_returns.x

# Calculating the RMSE (Root Mean Squared Error) for general data using general random forest model
rf_rmse_all <- sqrt(mean((predictions_rf_all - rf_actual_values_all)^2))
cat("Mean Squared Forecast Error (MSFE) for Random Forest:", rf_rmse_all, "\n")

```

```{r}
train_data_ts_subset <- train_data_ts[, !names(train_data_ts) %in% c("excess_returns.x", "time", "lag_returns","lag_sp_index")]
# Create an explainer object
explainer <- explain(model = rf_model_all,
                     data = train_data_ts_subset,
                     y = train_data_ts$excess_returns.x,
                     label = "Regression Tree Model")

# Calculate permutation feature importance
perm_importance <- variable_importance(explainer)

# Print the result
print(perm_importance)

# Generate model explanations
model_explanations <- DALEX::model_parts(explainer)

# Print variable importance plot
plot(model_explanations)

```




### ML for quarterly


```{r}
# Drop columns using subset
#excessquarter <- subset(excessquarter, select = -c(predicted_excess_returns_rt, predicted_excess_returns_rf))

# Traing and testing set
split_point <- round(0.8 * nrow(excessquarter))

# Create training and testing sets based on the split point
train_data_er <- subset(excessquarter, time <= excessquarter$time[split_point])
test_data_er <- subset(excessquarter, time > excessquarter$time[split_point])
# Define the formula
max_lag <- 10
formula_er <- as.formula(paste("excess_returns ~", paste(paste("er_lag_", 1:max_lag, sep = ""), collapse = " + ")))
```

```{r}
train_data_er
```

# Regression tree


```{r, warning=FALSE}
set.seed(128)

rt_model <- rpart(formula_er, data = train_data_er,control = rpart.control(cp = 0.1))

# Predictions
rt_predictions <- predict(rt_model, newdata = test_data_er)

# Add the predictions to excessmonth based on time
excessquarter$predicted_excess_returns_rt <- NA  
# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_er)) {
  time_index <- which(excessquarter$time == test_data_er$time[i])
  if (length(time_index) > 0) {
    excessquarter[time_index, "predicted_excess_returns_rt"] <- rt_predictions[i]
    
  }
}
    # Plot results
ggplot(excessquarter, aes(x = time)) +
  geom_line(aes(y = excess_returns, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rt, color = "Predicted")) +
  labs(title = "Actual vs. Predicted Excess Returns using Regression Tree",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))

# Calculate MSFE

rt_actual_values <- test_data_er$excess_returns
rt_rmse <- sqrt(mean((rt_predictions - rt_actual_values)^2))

cat("Mean Squared Forecast Error (MSFE):", rt_rmse, "\n")
```



```{r}

# Calculate and plot important using DALEX
train_data_er_subset <- train_data_er[, !names(train_data_er) %in% c("excess_returns", "time")]
explainer <- explain(model = rt_model,
                     data = train_data_er_subset,
                     y = train_data_er$excess_returns,
                     label = "Regression Tree Model")

# Calculate permutation feature importance
perm_importance <- variable_importance(explainer)

print(perm_importance)
model_explanations <- DALEX::model_parts(explainer)
plot(model_explanations)

```


## Random forest



```{r}
train_data_er <- na.omit(train_data_er)
test_data_er <- na.omit(test_data_er)
```


```{r, warning=FALSE}
set.seed(512)

rf_model <- randomForest(
  formula_er, 
  data = train_data_er,
  ntree = 110, 
  mtry = 2,  
  importance = TRUE 
)


rf_predictions <- predict(rf_model, newdata = test_data_er)

excessquarter$predicted_excess_returns_rf <- NA

# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_er)) {
  time_index <- which(excessquarter$time == test_data_er$time[i])
  if (length(time_index) > 0) {
    excessquarter[time_index, "predicted_excess_returns_rf"] <- rf_predictions[i]
  }
}
# Plot results
ggplot(excessquarter, aes(x = time)) +
  geom_line(aes(y = excess_returns, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rf, color = "Predicted"), linetype = "dashed") +
  labs(title = "Actual vs. Predicted Excess Returns using Random Forest",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))

rf_actual_values <- test_data_er$excess_returns
rf_msfe <- sqrt(mean((rf_predictions - rf_actual_values)^2))
cat("Mean Squared Forecast Error (MSFE):", rf_msfe, "\n")

```


```{r}

explainer2 <- explain(model = rf_model,
                      data = train_data_er_subset,
                      y = train_data_er$excess_returns,
                      label = "Random Forest Model")

# Calculate permutation feature importance
perm_importance2 <- variable_importance(explainer2)

print(perm_importance2)

# Generate model explanations
model_explanations2 <- DALEX::model_parts(explainer2)
plot(model_explanations2)

```


## Forecasting for the whole data


```{r}
#ts_quarter <- subset(ts_quarter, select = -c(predicted_excess_returns_rt, predicted_excess_returns_rf))
# Traing and testing set
split_point <- round(0.8 * nrow(ts_quarter))

# Create training and testing sets based on the split point
train_data_ts <- subset(ts_quarter, time <= ts_quarter$time[split_point])
test_data_ts <- subset(ts_quarter, time > ts_quarter$time[split_point])
target_variable <- "excess_returns.x"

predictor_variables <- setdiff(names(ts_quarter), c(target_variable, "lag_returns", "time", "lag_sp_index"))

formula_all <- as.formula(paste(target_variable, "~", paste(paste(predictor_variables, collapse = " + "), collapse = " + "))) 
```

## Regression tree

```{r, warning=FALSE}
set.seed(1024)


rt_model_all <- rpart(formula_all, data = train_data_ts, control = rpart.control(cp = 0.022))

# Predictions using the general data regression tree model
rt_predictions_all <- predict(rt_model_all, newdata = test_data_ts)


ts_quarter$predicted_excess_returns_rt <- NA

# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_ts)) {
  time_index <- which(ts_quarter$time == test_data_ts$time[i])
  if (length(time_index) > 0) {
    ts_quarter[time_index, "predicted_excess_returns_rt"] <- rt_predictions_all[i]
  }
}

ggplot(ts_quarter, aes(x = time)) +
  geom_line(aes(y = excess_returns.x, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rt, color = "Predicted")) +
  labs(title = "Actual vs. Predicted Excess Returns using Regression Tree all",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))



# calculate MSFE

rt_actual_values_all <- test_data_ts$excess_returns.x
rt_msfe_all <- sqrt(mean((rt_predictions_all - rt_actual_values_all)^2))

cat("Mean Squared Forecast Error (MSFE) for Regression Tree:", rt_msfe_all, "\n")
```


```{r}

# Calculate feature importance
train_data_ts_subset <- train_data_ts[, !names(train_data_ts) %in% c("excess_returns.x", "time", "lag_returns","lag_sp_index")]

# Create an explainer object
explainer <- explain(model = rt_model_all,
                     data = train_data_ts_subset,
                     y = train_data_ts$excess_returns.x,
                     label = "Regression Tree Model")

# Calculate permutation feature importance
perm_importance <- variable_importance(explainer)
print(perm_importance)

# Generate model explanations
model_explanations <- DALEX::model_parts(explainer)
plot(model_explanations)

```


## Random Forest

```{r, warning=FALSE}
set.seed(512)

# Building the Random Forest model for general data
rf_model_all <- randomForest(
  formula_all,
  data = train_data_ts,
  ntree = 120,  
  mtry = 2,  
  importance = TRUE  
)


predictions_rf_all <- predict(rf_model_all, newdata = test_data_ts)

ts_quarter$predicted_excess_returns_rf <- NA

# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_ts)) {
  time_index <- which(ts_quarter$time == test_data_ts$time[i])
  if (length(time_index) > 0) {
    ts_quarter[time_index, "predicted_excess_returns_rf"] <- predictions_rf_all[i]
  }
}

ggplot(ts_quarter, aes(x = time)) +
  geom_line(aes(y = excess_returns.x, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rf, color = "Predicted"), linetype = "dashed") +
  labs(title = "Actual vs. Predicted Excess Returns using Random Forest all",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))

# Actual values from the test set for general data
rf_actual_values_all <- test_data_ts$excess_returns.x

# Calculating the RMSE (Root Mean Squared Error) for general data using general random forest model
rf_rmse_all <- sqrt(mean((predictions_rf_all - rf_actual_values_all)^2))
cat("Mean Squared Forecast Error (MSFE) for Random Forest:", rf_rmse_all, "\n")

```

```{r}
train_data_ts_subset <- train_data_ts[, !names(train_data_ts) %in% c("excess_returns.x", "time", "lag_returns","lag_sp_index")]
# Create an explainer object
explainer <- explain(model = rf_model_all,
                     data = train_data_ts_subset,
                     y = train_data_ts$excess_returns.x,
                     label = "Regression Tree Model")

# Calculate permutation feature importance
perm_importance <- variable_importance(explainer)

# Print the result
print(perm_importance)

# Generate model explanations
model_explanations <- DALEX::model_parts(explainer)

# Print variable importance plot
plot(model_explanations)

```








### ML for year

```{r}
# Traing and testing set
split_point <- round(0.8 * nrow(excessyear))

# Create training and testing sets based on the split point
train_data_er <- subset(excessyear, time <= excessyear$time[split_point])
test_data_er <- subset(excessyear, time > excessyear$time[split_point])
# Define the formula
max_lag <- 10
formula_er <- as.formula(paste("excess_returns ~", paste(paste("er_lag_", 1:max_lag, sep = ""), collapse = " + ")))
```

# Regression tree

```{r, warning=FALSE}
set.seed(128)

rt_model <- rpart(formula_er, data = train_data_er,control = rpart.control(cp = 0.065))

# Predictions
rt_predictions <- predict(rt_model, newdata = test_data_er)

# Add the predictions to excessyear based on time
excessyear$predicted_excess_returns_rt <- NA  
# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_er)) {
  time_index <- which(excessyear$time == test_data_er$time[i])
  if (length(time_index) > 0) {
    excessyear[time_index, "predicted_excess_returns_rt"] <- rt_predictions[i]
    
  }
}
    # Plot results
ggplot(excessyear, aes(x = time)) +
  geom_line(aes(y = excess_returns, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rt, color = "Predicted")) +
  labs(title = "Actual vs. Predicted Excess Returns using Regression Tree",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))

# Calculate MSFE

rt_actual_values <- test_data_er$excess_returns
rt_rmse <- sqrt(mean((rt_predictions - rt_actual_values)^2))

cat("Mean Squared Forecast Error (MSFE):", rt_rmse, "\n")
```


```{r}

# Calculate and plot important using DALEX
train_data_er_subset <- train_data_er[, !names(train_data_er) %in% c("excess_returns", "time")]
explainer <- explain(model = rt_model,
                     data = train_data_er_subset,
                     y = train_data_er$excess_returns,
                     label = "Regression Tree Model")

# Calculate permutation feature importance
perm_importance <- variable_importance(explainer)

print(perm_importance)
model_explanations <- DALEX::model_parts(explainer)
plot(model_explanations)

```


## Random forest

```{r}
train_data_er <- na.omit(train_data_er)
test_data_er <- na.omit(test_data_er)
```


```{r, warning=FALSE}
set.seed(512)

rf_model <- randomForest(
  formula_er, 
  data = train_data_er,
  ntree = 60, 
  mtry = 3,  
  importance = TRUE 
)


rf_predictions <- predict(rf_model, newdata = test_data_er)

excessyear$predicted_excess_returns_rf <- NA

# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_er)) {
  time_index <- which(excessyear$time == test_data_er$time[i])
  if (length(time_index) > 0) {
    excessyear[time_index, "predicted_excess_returns_rf"] <- rf_predictions[i]
  }
}
# Plot results
ggplot(excessyear, aes(x = time)) +
  geom_line(aes(y = excess_returns, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rf, color = "Predicted"), linetype = "dashed") +
  labs(title = "Actual vs. Predicted Excess Returns using Random Forest",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))

rf_actual_values <- test_data_er$excess_returns
rf_msfe <- sqrt(mean((rf_predictions - rf_actual_values)^2))
cat("Mean Squared Forecast Error (MSFE):", rf_msfe, "\n")

```


```{r}

explainer2 <- explain(model = rf_model,
                      data = train_data_er_subset,
                      y = train_data_er$excess_returns,
                      label = "Random Forest Model")

# Calculate permutation feature importance
perm_importance2 <- variable_importance(explainer2)

print(perm_importance2)

# Generate model explanations
model_explanations2 <- DALEX::model_parts(explainer2)
plot(model_explanations2)

```


## Forecasting for the whole data


```{r}

# Traing and testing set
split_point <- round(0.8 * nrow(ts_year))

# Create training and testing sets based on the split point
train_data_ts <- subset(ts_year, time <= ts_year$time[split_point])
test_data_ts <- subset(ts_year, time > ts_year$time[split_point])
target_variable <- "excess_returns.x"

predictor_variables <- setdiff(names(ts_year), c(target_variable, "lag_returns", "time", "lag_sp_index"))

formula_all <- as.formula(paste(target_variable, "~", paste(paste(predictor_variables, collapse = " + "), collapse = " + "))) 
```



## Regression tree

```{r, warning=FALSE}
set.seed(1024)


rt_model_all <- rpart(formula_all, data = train_data_ts, control = rpart.control(cp = 0.01))

# Predictions using the general data regression tree model
rt_predictions_all <- predict(rt_model_all, newdata = test_data_ts)


ts_year$predicted_excess_returns_rt <- NA

# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_ts)) {
  time_index <- which(ts_year$time == test_data_ts$time[i])
  if (length(time_index) > 0) {
    ts_year[time_index, "predicted_excess_returns_rt"] <- rt_predictions_all[i]
  }
}

ggplot(ts_year, aes(x = time)) +
  geom_line(aes(y = excess_returns.x, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rt, color = "Predicted")) +
  labs(title = "Actual vs. Predicted Excess Returns using Regression Tree all",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))



# calculate MSFE

rt_actual_values_all <- test_data_ts$excess_returns.x
rt_msfe_all <- sqrt(mean((rt_predictions_all - rt_actual_values_all)^2))

cat("Mean Squared Forecast Error (MSFE) for Regression Tree:", rt_msfe_all, "\n")
```


```{r}

# Calculate feature importance
train_data_ts_subset <- train_data_ts[, !names(train_data_ts) %in% c("excess_returns.x", "time", "lag_returns","lag_sp_index")]

# Create an explainer object
explainer <- explain(model = rt_model_all,
                     data = train_data_ts_subset,
                     y = train_data_ts$excess_returns.x,
                     label = "Regression Tree Model")

# Calculate permutation feature importance
perm_importance <- variable_importance(explainer)
print(perm_importance)

# Generate model explanations
model_explanations <- DALEX::model_parts(explainer)
plot(model_explanations)

```


## Random Forest

```{r, warning=FALSE}
set.seed(512)

# Building the Random Forest model for general data
rf_model_all <- randomForest(
  formula_all,
  data = train_data_ts,
  ntree = 65,  
  mtry = 3,  
  importance = TRUE  
)


predictions_rf_all <- predict(rf_model_all, newdata = test_data_ts)

ts_year$predicted_excess_returns_rf <- NA

# Match predictions to corresponding rows based on time
for (i in 1:nrow(test_data_ts)) {
  time_index <- which(ts_year$time == test_data_ts$time[i])
  if (length(time_index) > 0) {
    ts_year[time_index, "predicted_excess_returns_rf"] <- predictions_rf_all[i]
  }
}

ggplot(ts_year, aes(x = time)) +
  geom_line(aes(y = excess_returns.x, color = "Actual")) +
  geom_line(aes(y = predicted_excess_returns_rf, color = "Predicted"), linetype = "dashed") +
  labs(title = "Actual vs. Predicted Excess Returns using Random Forest all",
       x = "Time",
       y = "Excess Returns") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))

# Actual values from the test set for general data
rf_actual_values_all <- test_data_ts$excess_returns.x

# Calculating the RMSE (Root Mean Squared Error) for general data using general random forest model
rf_rmse_all <- sqrt(mean((predictions_rf_all - rf_actual_values_all)^2))
cat("Mean Squared Forecast Error (MSFE) for Random Forest:", rf_rmse_all, "\n")

```

```{r}
train_data_ts_subset <- train_data_ts[, !names(train_data_ts) %in% c("excess_returns.x", "time", "lag_returns","lag_sp_index")]
# Create an explainer object
explainer <- explain(model = rf_model_all,
                     data = train_data_ts_subset,
                     y = train_data_ts$excess_returns.x,
                     label = "Regression Tree Model")

# Calculate permutation feature importance
perm_importance <- variable_importance(explainer)

# Print the result
print(perm_importance)

# Generate model explanations
model_explanations <- DALEX::model_parts(explainer)

# Print variable importance plot
plot(model_explanations)

```






#### project 3


```{r}
DataMonthly <- read_excel("~/Desktop/case study/PredictorData2022.xlsx", sheet = "Monthly")
DataQuarterly <- read_excel("~/Desktop/case study/PredictorData2022.xlsx", sheet = "Quarterly")
DataAnnual <- read_excel( "~/Desktop/case study/PredictorData2022.xlsx", sheet = "Annual")

new_colnames_dict <- c(
  "Time" = "yyyymm",
  "Time" = "yyyyq",
  "Time" = "yyyy",
  "SP500_Index" = "Index",
  "Dividends_12MonthSum" = "D12",
  "Earnings_12MonthSum" = "E12",
  "BookToMarket_Ratio" = "b/m",
  "TreasuryBill_Rate" = "tbl",
  "AAA_CorporateBond_Yield" = "AAA",
  "BAA_CorporateBond_Yield" = "BAA",
  "LongTermGovBond_Yield" = "lty",
  "NetEquityExpansion" = "ntis",
  "RiskFree_Rate" = "Rfree",
  "Inflation_CPI" = "infl",
  "LongTermRateOfReturn" = "ltr",
  "CorporateBond_Return" = "corpr",
  "StockVariance" = "svar",
  "CrossSectionalPremium" = "csp",
  "ConsumptionWealthIncomeRatio" = "cay", #check these variables
  "InvestmentCapitalRatio" = "ik",
  "Dividend3YearPriceRatio" = "D3",
  "Earnings3YearPriceRatio" = "E3",
  "ConsumptionWealthIncomeRatioMonthly" = "caym",
  "PercentageEquityIssuing" = "eqis"
)


filtered_dict_monthly <- new_colnames_dict[new_colnames_dict %in% colnames(DataMonthly)]
DataMonthly <- rename(DataMonthly, !!!filtered_dict_monthly)

filtered_dict_monthly <- new_colnames_dict[new_colnames_dict %in% colnames(DataQuarterly)]
DataQuarterly <- rename(DataQuarterly, !!!filtered_dict_monthly)

filtered_dict_monthly <- new_colnames_dict[new_colnames_dict %in% colnames(DataAnnual)]
DataAnnual <- rename(DataAnnual, !!!filtered_dict_monthly)


convert_to_numeric <- function(data) {
  for (i in names(data)) {
    if (class(data[[i]]) == "character") {
      data[[i]] <- as.numeric(data[[i]])
    }
  }
  return(data)
}

DataMonthly %<>% convert_to_numeric()
DataQuarterly %<>% convert_to_numeric()
DataAnnual %<>% convert_to_numeric()


DataMonthly$Time <- zoo::as.yearmon(as.character(DataMonthly$Time), format="%Y%m")
DataMonthly %<>% select(-CRSP_SPvw, -CRSP_SPvwx)


DataQuarterly$Time <- zoo::as.yearqtr(as.character(DataQuarterly$Time), format="%Y%q")
DataQuarterly %<>% select(-CRSP_SPvw, -CRSP_SPvwx, -ConsumptionWealthIncomeRatio,-InvestmentCapitalRatio, 
                          -Dividend3YearPriceRatio, -Earnings3YearPriceRatio)


DataAnnual$Time <- zoo::as.yearmon(paste0(as.character(DataAnnual$Time), "-01"), format="%Y-%m")
DataAnnual %<>% select(-CRSP_SPvw, -CRSP_SPvwx, -ConsumptionWealthIncomeRatio,-InvestmentCapitalRatio)


#Calculate Returns
calculate_returns <- function(input){
  input %<>% mutate(returns = as.vector(quantmod::Delt(SP500_Index))) 
  input %<>% mutate(ExcessReturn = returns - RiskFree_Rate)
  input %<>% select(-returns, -RiskFree_Rate, -SP500_Index)
  return(input)
}

lag_predictors <- function(input){
  output <- input %>%
    mutate(across(-c(Time, ExcessReturn), lag, .names = "lag_{.col}")) %>% 
    select(Time, ExcessReturn, starts_with("lag_")) %>% 
    slice(-1) 
  return(output)
}


DataMonthly %<>% calculate_returns()
DataQuarterly %<>% calculate_returns()
DataAnnual %<>% calculate_returns()


#Filtering Data to Handle NULL values and Dropping lag_CrossSectionalPremium
DataMonthly <- subset(DataMonthly, select = -c(CrossSectionalPremium))
DataQuarterly <- subset(DataQuarterly, select = -c(CrossSectionalPremium))
DataAnnual <- subset(DataAnnual, select = -c(CrossSectionalPremium))



DataMonthly %<>% lag_predictors()
DataQuarterly %<>% lag_predictors()
DataAnnual %<>% lag_predictors()



n_lags <- 10


# Generate lagged columns using base R
for (i in 1:n_lags) {
  DataMonthly[[paste0("lag_", i)]] <- c(rep(NA, i), head(DataMonthly$ExcessReturn, -i))
  DataQuarterly[[paste0("lag_", i)]] <- c(rep(NA, i), head(DataQuarterly$ExcessReturn, -i))
  DataAnnual[[paste0("lag_", i)]] <- c(rep(NA, i), head(DataAnnual$ExcessReturn, -i))    
}



# Remove rows with NA resulting from lag creation
DataMonthly <- DataMonthly[complete.cases(DataMonthly$lag_10), ]

DataQuarterly <- DataQuarterly[complete.cases(DataQuarterly$lag_10), ]

DataAnnual <- DataAnnual[complete.cases(DataAnnual$lag_10), ]


#Filtering Data After 1927
DataMonthly <- DataMonthly[DataMonthly$Time >= zoo::as.yearmon("1927-01", format = "%Y-%m"), ]
threshold_yearqtr <- as.yearqtr("1927 Q1", format = "%Y Q%q")
threshold_date <- as.Date(as.yearmon(threshold_yearqtr))
DataQuarterly <- DataQuarterly[as.Date(DataQuarterly$Time) >= threshold_date, ]
DataAnnual <- DataAnnual[DataAnnual$Time >= zoo::as.yearmon("1927-01", format = "%Y-%m"), ]


n_lags <- 10
selected_columns <- c("Time","ExcessReturn",paste0("lag_", 1:n_lags))
Monthly_lagged_data <- DataMonthly[selected_columns]
Quarterly_lagged_data <- DataQuarterly[selected_columns]
Annual_lagged_data <- DataAnnual[selected_columns]

tail(DataMonthly)
```


##ARmodel

```{r}
AR_rolling_forecast <- function(myTimeSeries, window_size, order) {
  all_predictions <- numeric(0)
  
  for (i in seq(nrow(myTimeSeries) - window_size + 1, nrow(myTimeSeries), 1)) {
    start_window <- i - window_size + 1
    end_window <- i - 1
    window_data <- myTimeSeries[start_window:end_window, ]
    
    # Fit AR model
    ar_model <- Arima(window_data$ExcessReturn, order = order)
    
    next_window <- myTimeSeries[end_window + 1, ]
    
    # Make predictions for the next observation
    next_window_prediction <- forecast(ar_model, h = 1)$mean
    all_predictions <- c(all_predictions, next_window_prediction)
  }
  
  actual_values <- tail(myTimeSeries, window_size)
  residuals <- actual_values$ExcessReturn - all_predictions
  rmse <- sqrt(mean(residuals^2))
  
  time_index <- seq_along(actual_values)
  plot_data <- data.frame(Time = actual_values$Time, ExcessReturn = actual_values$ExcessReturn, Predicted = all_predictions, Residuals = residuals)  
  
  plot <- ggplot(plot_data, aes(x = Time)) +
    geom_line(aes(y = ExcessReturn), color = "grey", size = 1) +
    geom_line(aes(y = Predicted), color = "blue", linetype = "dashed", size = 1) +
    labs(x = "Time", y = "Excess Returns") +
    ggtitle("Actual vs Predicted Excess Returns over Time") +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14),
      axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
    scale_color_manual(values = c("blue", "red"))
  
  return(list(plot = plot, rmse = rmse, residuals = residuals))
}

```

```{r}
ar_month <- AR_rolling_forecast(DataMonthly, 120, c(3, 0, 0))
print(ar_month$rmse)

ar_month_plot <- ar_month$plot
plot_name <- "AR Monthly Rolling Forecast"

plot(ar_month_plot, main = plot_name)
```


```{r}
ar_quar <- AR_rolling_forecast(Quarterly_lagged_data, 40,c(4,0,0))
ar_quar$rmse
ar_quar$plot
ggsave("ARq.png", plot = ar_quar$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
ar_ann <- AR_rolling_forecast(Annual_lagged_data, 10,c(1,0,0))
ar_ann$rmse
ar_ann$plot
ggsave("ARy.png", plot = ar_ann$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
RT_rolling_forecast <- function(myTimeSeries, window_size,complexity) {
  all_predictions <- numeric(0)
  
  # Start the loop from the 10th year from the end
  for (i in seq(nrow(myTimeSeries) - window_size + 1, nrow(myTimeSeries), 1)) {
    start_window <- i - window_size + 1
    end_window <- i - 1
    window_data <- myTimeSeries[start_window:end_window, ]
    
    # Fit an rpart (single decision tree) model
    rt_model <- rpart(ExcessReturn ~ ., data = window_data, control = rpart.control(cp = complexity))
    
    next_window <- myTimeSeries[end_window + 1, ]
    next_window_predictors <- next_window[, -which(names(next_window) == "ExcessReturn")]
    
    # Ensure the length of 'next_window_predictors' matches the number of predictors
    next_window_prediction <- predict(rt_model, next_window_predictors)
    all_predictions <- c(all_predictions, next_window_prediction)
  }
  
  # Assuming you have the actual ExcessReturn values for comparison
  actual_values <- tail(myTimeSeries, window_size)
  residuals <- actual_values$ExcessReturn - all_predictions
  rmse <- sqrt(mean(residuals^2))
  plot_data <- data.frame(Time = actual_values$Time, ExcessReturn = actual_values$ExcessReturn, Predicted = all_predictions)  
  
  # Plot
  plot <- ggplot(plot_data, aes(x = Time)) +
    geom_line(aes(y = ExcessReturn), color = "grey", size = 1) +
    geom_line(aes(y = Predicted), color = "blue", linetype = "dashed", size = 1) +
    labs(x = "Time", y = "Excess Returns") +
    ggtitle("Actual vs Predicted Excess Returns over Time") +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14),
      axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
    scale_color_manual(values = c("blue", "red"))
  
  return(list(plot = plot, rmse = rmse, residuals = residuals))
}
```

```{r}

library(rpart)

```


```{r}
tree_mlag <- RT_rolling_forecast(Monthly_lagged_data, 120,0.009)
tree_mlag$rmse
tree_mlag$plot
ggsave("RTm_lag.png", plot = tree_mlag$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
tree_qlag <- RT_rolling_forecast(Quarterly_lagged_data, 40,0.1)
tree_qlag$rmse
tree_qlag$plot
ggsave("RTq_lag.png", plot = tree_qlag$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
tree_ylag <- RT_rolling_forecast(Annual_lagged_data, 10,0.065)
tree_ylag$rmse
tree_ylag$plot
ggsave("RTy_lag.png", plot = tree_ylag$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
tree_mall <- RT_rolling_forecast(DataMonthly, 120,0.009)
tree_mall$rmse
tree_mall$plot
ggsave("RTm_all.png", plot = tree_mall$plot, width = 24, height = 16, units = "in", dpi = 400)
```


```{r}
tree_qall <- RT_rolling_forecast(DataQuarterly, 40,0.022)
tree_qall$rmse
tree_qall$plot
ggsave("RTq_all.png", plot = tree_qall$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
tree_yall <- RT_rolling_forecast(DataAnnual, 10,0.01)
tree_yall$rmse
tree_yall$plot
ggsave("RTy_all.png", plot = tree_yall$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
RF_rolling_forecast <- function(myTimeSeries, window_size, tree) {
  all_predictions <- numeric(0)
  
  # Start the loop from the 10th year from the end
  for (i in seq(nrow(myTimeSeries) - window_size + 1, nrow(myTimeSeries), 1)) {
    start_window <- i - window_size + 1
    end_window <- i - 1
    window_data <- myTimeSeries[start_window:end_window, ]
    
    rf_model <- randomForest(ExcessReturn ~ ., data = window_data, ntree= tree)
    
    next_window <- myTimeSeries[end_window + 1, ]
    next_window_predictors <- next_window[, -which(names(next_window) == "ExcessReturn")]
    
    # Ensure the length of 'next_window_predictors' matches the number of predictors
    next_window_prediction <- predict(rf_model, next_window_predictors)
    all_predictions <- c(all_predictions, next_window_prediction)
  }
  
# Assuming you have the actual ExcessReturn values for comparison
actual_values <- tail(myTimeSeries, window_size)
residuals <- actual_values$ExcessReturn - all_predictions
rmse <- sqrt(mean(residuals^2))
  time_index <- seq_along(actual_values)
  plot_data <- data.frame(Time = actual_values$Time, ExcessReturn = actual_values$ExcessReturn, Predicted = all_predictions)  
  
  # Plot
  plot <- ggplot(plot_data, aes(x = Time)) +
    geom_line(aes(y = ExcessReturn), color = "grey", size = 1) +
    geom_line(aes(y = Predicted), color = "blue", linetype = "dashed", size = 1) +
    labs(x = "Time", y = "Excess Returns") +
    ggtitle("Actual vs Predicted Excess Returns over Time") +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14),
      axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
    scale_color_manual(values = c("blue", "red"))
    
  return(list(plot = plot, rmse = rmse, residuals = residuals))
    
}
```

```{r}
library(randomForest)
```

```{r}
rf_mlag <- RF_rolling_forecast(Monthly_lagged_data, 120,162)
rf_mlag$rmse
rf_mlag$plot
ggsave("RForestm_lag.png", plot = rf_mlag$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
rf_qlag <- RF_rolling_forecast(Quarterly_lagged_data, 40,110)
rf_qlag$rmse
rf_qlag$plot
ggsave("RForestq_lag.png", plot = rf_qlag$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
rf_ylag <- RF_rolling_forecast(Annual_lagged_data, 10,60)
rf_ylag$rmse
rf_ylag$plot
ggsave("RForesty_lag.png", plot = rf_ylag$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
rf_mall <- RF_rolling_forecast(DataMonthly, 120,320)
rf_mall$rmse
rf_mall$plot
ggsave("RForestm_all.png", plot = rf_mall$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
rf_qall <- RF_rolling_forecast(DataQuarterly, 40,120)
rf_qall$rmse
rf_qall$plot
ggsave("RForestq_all.png", plot = rf_qall$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
rf_yall <- RF_rolling_forecast(DataAnnual, 10,65)
rf_yall$rmse
rf_yall$plot
ggsave("RForesty_all.png", plot = rf_yall$plot, width = 24, height = 16, units = "in", dpi = 400)
```


```{r}

# Function to get the time span
get_time_span <- function(data_input, model_input){
  coefficients_names <- model_input %>% coef() %>% names() %>% setdiff("(Intercept)")
  complete_cases <- which(complete.cases(data_input[c("ExcessReturn", coefficients_names)]))
  used_rows <- row.names(model_input$model)
  removed_rows <- setdiff(complete_cases, as.numeric(used_rows))
  included_time_spans <- data_input$Time[as.numeric(used_rows)]
  output <- paste(included_time_spans %>% min() %>% year() %>% as.character(), "-", included_time_spans %>% max() %>% year() %>% as.character())
  return(output)
}

# Function for forward stepwise variable selection
stepwise_function <- function(input) {
  input_name <- deparse(substitute(input))
  
  model <- step(object = lm(ExcessReturn ~ 1, data = input %>% na.omit()), 
                scope = paste("ExcessReturn ~", 
                              paste(c(names(input %>% select(-ExcessReturn, -Time))), collapse = " + ")) %>% as.formula(),
                direction = "forward", trace = FALSE, k = 2) 
  
  # Extract relevant information from the lm object
  coefficients <- coef(model)
  residuals <- model$residuals
  r_squared <- summary(model)$r.squared
  
  output <- list(
    Data = get_time_span(data_input = input, model_input = model),
    MSFE = mean(residuals^2)^0.5,
    R2 = r_squared,
    Coefficients = coefficients,
    model = model
  )

  #print(summary(model))
  return(output)
}


# Function for one-step-ahead forecasting using forward stepwise variable selection

forward_stepwise_rolling_forecast <- function(myTimeSeries, window_size) {
  all_predictions <- numeric(0)

  for (i in seq(nrow(myTimeSeries) - window_size + 1, nrow(myTimeSeries), 1)) {
    start_window <- i - window_size + 1
    end_window <- i - 1
    window_data <- myTimeSeries[start_window:end_window, ]

    # Fit forward stepwise model
    stepwise_model <- stepwise_function(input = window_data)

    # Make predictions for the next observation
    predictors <- names(stepwise_model$model$coefficients)[-1]  # Exclude intercept
    formula_str <- as.formula(paste("ExcessReturn ~", paste(predictors, collapse = " + ")))
    next_window_prediction <- predict(stepwise_model$model, newdata = myTimeSeries[i, ], type = "response", formula = formula_str)
    all_predictions <- c(all_predictions, next_window_prediction)
  }

  actual_values <- tail(myTimeSeries, window_size)
  residuals <- actual_values$ExcessReturn - all_predictions
  rmse <- sqrt(mean(residuals^2))

  time_index <- seq_along(actual_values)
  plot_data <- data.frame(Time = actual_values$Time, ExcessReturn = actual_values$ExcessReturn, Predicted = all_predictions, Residuals = residuals)

  plot <- ggplot(plot_data, aes(x = Time)) +
    geom_line(aes(y = ExcessReturn), color = "grey", size = 1) +
    geom_line(aes(y = Predicted), color = "blue", linetype = "dashed", size = 1) +
    labs(x = "Time", y = "Excess Returns") +
    ggtitle("Actual vs Predicted Excess Returns over Time") +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14),
      axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
    scale_color_manual(values = c("blue", "red"))

  return(list(plot = plot, rmse = rmse, residuals = residuals))
}

```

```{r}
# Monthly
myTimeSeries <- DataMonthly  # Replace with your actual time series data
window_size <- 120  # Replace with your desired window size for the rolling forecast

stepm <- forward_stepwise_rolling_forecast(myTimeSeries, window_size)
print(stepm$rmse)
print(stepm$residuals)
print(stepm$plot)
ggsave("stepm.png", plot = stepm$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
# Quarterly
myTimeSeries <- DataQuarterly  # Replace with your actual time series data
window_size <- 40  # Replace with your desired window size for the rolling forecast

stepq <- forward_stepwise_rolling_forecast(myTimeSeries, window_size)
print(stepq$rmse)
print(stepq$residuals)
print(stepq$plot)
ggsave("stepq.png", plot = stepq$plot, width = 24, height = 16, units = "in", dpi = 400)
```


```{r}
# DataAnnual
myTimeSeries <- DataAnnual  # Replace with your actual time series data
window_size <- 10  # Replace with your desired window size for the rolling forecast

stepy <- forward_stepwise_rolling_forecast(myTimeSeries, window_size)
print(stepy$rmse)
print(stepy$residuals)
print(stepy$plot)
ggsave("stepy.png", plot = stepy$plot, width = 24, height = 16, units = "in", dpi = 400)
```

```{r}
library(lubridate)
library(tidyverse)
library(Matrix)
library(tibble)
```

```{r}
# Assuming `stepy$residuals` and `arm$residuals` are your two sets of residuals
residuals_df <- data.frame(AR_m=ar_month$residuals, Step_m = stepm$residuals, RT_lagm=tree_mlag$residuals, RT_allm=tree_mall$residuals, RF_lagm=rf_mlag$residuals,  RF_allm=rf_mall$residuals)

```


```{r}
residuals_df_quar <- data.frame(AR_quar=ar_quar$residuals, Step_quar = stepq$residuals, RT_lagquar=tree_qlag$residuals, RT_allquar=tree_qall$residuals, RF_lagquar=rf_qlag$residuals, RF_allquar=rf_qall$residuals
                           )
```

```{r}
residuals_df_ann <- data.frame(AR_ann=ar_ann$residuals, Step_ann = stepy$residuals, RT_lagann=tree_ylag$residuals, RT_allann=tree_yall$residuals,  RF_lagann=rf_ylag$residuals, RF_allann=rf_yall$residuals)
```



```{r}
dm_test <- function(error_a, error_b, hmax = 1, power = 1) {
    # Calc loss of model a and b (L-power norm) across all hours
    loss_a <- apply(abs(as.matrix(error_a))^power, 1, sum)^(1 / power)
    loss_b <- apply(abs(as.matrix(error_b))^power, 1, sum)^(1 / power)
    
    # Calculate delta
    delta <- loss_a - loss_b
    sum(delta)
    # Estimate variance of delta
    delta_var <- var(delta) / length(delta)

    # Calc test statistic
    statistic <- mean(delta, na.rm = TRUE) / sqrt(delta_var)

    # Calc p-value
    delta_length <- length(delta)
    k <- ((delta_length + 1 - 2 * hmax +
        (hmax / delta_length) * (hmax - 1)) / delta_length)^(1 / 2)
    statistic <- statistic * k
    p_value <- pt(statistic, df = delta_length - 1)

    # Return results
    return(list(stat = statistic, p.val = p_value))
}

```

```{r}
# Calculate the Diebold-Mariano test
dm_test_result <- dm_test(residuals_df$AR_month, residuals_df$Step_month)

# Print the result
print(dm_test_result)
```
### Monthly

```{r}
# Extract model names
model_names <- colnames(residuals_df)

# Define matrices to store results
dm_p_val <- matrix(NA, nrow = length(model_names), ncol = length(model_names))
dm_t_stat <- matrix(NA, nrow = length(model_names), ncol = length(model_names))

# Loop through all models
for (mod_a in seq_along(model_names)) {
    for (mod_b in seq_along(model_names)) {
        if (mod_a != mod_b) {  # Check if they are different models
            # Run the Diebold-Mariano test
            dm <- dm_test(residuals_df[, mod_a], residuals_df[, mod_b])
            
            # Store the results in matrices
            dm_p_val[mod_a, mod_b] <- dm$p.val
            dm_t_stat[mod_a, mod_b] <- dm$stat
        }
    }
}

# Convert matrices to data frames and add row/column names
dm_p_val_df <- as.data.frame(dm_p_val, row.names = model_names)
colnames(dm_p_val_df) <- model_names
dm_t_stat_df <- as.data.frame(dm_t_stat, row.names = model_names, col.names = model_names)
colnames(dm_t_stat_df) <- model_names
```


```{r}
dm_t_stat_df
```



```{r}

library(tibble)

# Extract model names
model_names <- rownames(dm_p_val_df)

# Create a tibble for plotting
dm_results_tibble <- expand.grid(mod_b = model_names, mod_a = model_names)
dm_results_tibble$value <- unlist(dm_p_val_df)

# Display the tibble
print(dm_results_tibble)

```


```{r}
# Create an empty matrix to store the p-values
dm_p_val_matrix <- matrix(NA, nrow = length(model_names), ncol = length(model_names))
rownames(dm_p_val_matrix) <- model_names
colnames(dm_p_val_matrix) <- model_names

# Fill in the matrix with p-values
for (mod_a in model_names) {
  for (mod_b in model_names) {
    if (mod_a != mod_b) {
      p_val <- dm_p_val_df[mod_a, mod_b]
      dm_p_val_matrix[mod_a, mod_b] <- p_val
    }
  }
}

# Display the matrix
print(dm_p_val_matrix)
```

```{r}
dm_results_tibble %>%
    ggplot(aes(x = mod_b, y = reorder(mod_a, desc(mod_a)), fill = value)) +
    geom_raster() +
    scale_fill_gradientn(
        name = "P_value",
        colours = c("#007900", "red"),
        na.value = "grey15",
        guide = guide_colourbar(
            title.vjust = 0.93,
            barwidth = 1,
            barheight = 15,
        ),
        breaks = seq(from = 0, to = .1, by = 0.01),
        limits = c(0, .1),
        oob = scales::squish
    ) + 
   theme(
        plot.title = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text = element_text(size = 11),  # Adjust the size as needed
        legend.text = element_text(size = 12),  # Adjust the size as needed
        legend.title = element_text(size = 14, face = "bold")  # Adjust the size and style as needed
    )


```

### quarterly

```{r}
## Calculate
# Extract model names
model_names <- colnames(residuals_df_quar)

# Define matrices to store results
dm_p_val <- matrix(NA, nrow = length(model_names), ncol = length(model_names))
dm_t_stat <- matrix(NA, nrow = length(model_names), ncol = length(model_names))

# Loop through all models
for (mod_a in seq_along(model_names)) {
    for (mod_b in seq_along(model_names)) {
        if (mod_a != mod_b) {  # Check if they are different models
            # Run the Diebold-Mariano test
            dm <- dm_test(residuals_df_quar[, mod_a], residuals_df_quar[, mod_b])
            
            # Store the results in matrices
            dm_p_val[mod_a, mod_b] <- dm$p.val
            dm_t_stat[mod_a, mod_b] <- dm$stat
        }
    }
}

# Convert matrices to data frames and add row/column names
dm_p_val_df <- as.data.frame(dm_p_val, row.names = model_names)
colnames(dm_p_val_df) <- model_names
dm_t_stat_df <- as.data.frame(dm_t_stat, row.names = model_names, col.names = model_names)
colnames(dm_t_stat_df) <- model_names

##tible
library(tibble)

# Extract model names
model_names <- rownames(dm_p_val_df)

# Create a tibble for plotting
dm_results_tibble <- expand.grid(mod_a = model_names, mod_b = model_names)
dm_results_tibble$value <- unlist(dm_p_val_df)

# Display the tibble
print(dm_results_tibble)


### Matrix
# Create an empty matrix to store the p-values
dm_p_val_matrix <- matrix(NA, nrow = length(model_names), ncol = length(model_names))
rownames(dm_p_val_matrix) <- model_names
colnames(dm_p_val_matrix) <- model_names

# Fill in the matrix with p-values
for (mod_a in model_names) {
  for (mod_b in model_names) {
    if (mod_a != mod_b) {
      p_val <- dm_p_val_df[mod_a, mod_b]
      dm_p_val_matrix[mod_a, mod_b] <- p_val
    }
  }
}

# Display the matrix
print(dm_p_val_matrix)


### Plot
dm_results_tibble %>%
    ggplot(aes(x = mod_b, y = reorder(mod_a, desc(mod_a)), fill = value)) +
    geom_raster() +
    scale_fill_gradientn(
        name = "Statistic",
        colours = c("#007900", "red"),
        na.value = "grey15",
        guide = guide_colourbar(
            title.vjust = 0.93,
            barwidth = 1,
            barheight = 10,
        ),
        breaks = seq(from = 0, to = .1, by = 0.01),
        limits = c(0, .1),
        oob = scales::squish
    ) + 
   theme(
        plot.title = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
    )


```


```{r}
## Calculate
# Extract model names
model_names <- colnames(residuals_df_ann)

# Define matrices to store results
dm_p_val <- matrix(NA, nrow = length(model_names), ncol = length(model_names))
dm_t_stat <- matrix(NA, nrow = length(model_names), ncol = length(model_names))

# Loop through all models
for (mod_a in seq_along(model_names)) {
    for (mod_b in seq_along(model_names)) {
        if (mod_a != mod_b) {  # Check if they are different models
            # Run the Diebold-Mariano test
            dm <- dm_test(residuals_df_ann[, mod_a], residuals_df_ann[, mod_b])
            
            # Store the results in matrices
            dm_p_val[mod_a, mod_b] <- dm$p.val
            dm_t_stat[mod_a, mod_b] <- dm$stat
        }
    }
}

# Convert matrices to data frames and add row/column names
dm_p_val_df <- as.data.frame(dm_p_val, row.names = model_names)
colnames(dm_p_val_df) <- model_names
dm_t_stat_df <- as.data.frame(dm_t_stat, row.names = model_names, col.names = model_names)
colnames(dm_t_stat_df) <- model_names

##tible
library(tibble)

# Extract model names
model_names <- rownames(dm_p_val_df)

# Create a tibble for plotting
dm_results_tibble <- expand.grid(mod_b = model_names, mod_a = model_names)
dm_results_tibble$value <- unlist(dm_p_val_df)

# Display the tibble
print(dm_results_tibble)


### Matrix
# Create an empty matrix to store the p-values
dm_p_val_matrix <- matrix(NA, nrow = length(model_names), ncol = length(model_names))
rownames(dm_p_val_matrix) <- model_names
colnames(dm_p_val_matrix) <- model_names

# Fill in the matrix with p-values
for (mod_a in model_names) {
  for (mod_b in model_names) {
    if (mod_a != mod_b) {
      p_val <- dm_p_val_df[mod_a, mod_b]
      dm_p_val_matrix[mod_a, mod_b] <- p_val
    }
  }
}

# Display the matrix
print(dm_p_val_matrix)


### Plot
dm_results_tibble %>%
    ggplot(aes(x = mod_b, y = reorder(mod_a, desc(mod_a)), fill = value)) +
    geom_raster() +
    scale_fill_gradientn(
        name = "Statistic",
        colours = c("#007900", "red"),
        na.value = "grey15",
        guide = guide_colourbar(
            title.vjust = 0.93,
            barwidth = 1,
            barheight = 10,
        ),
        breaks = seq(from = 0, to = .1, by = 0.01),
        limits = c(0, .1),
        oob = scales::squish
    ) + 
   theme(
        plot.title = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text = element_text(size = 10),  
        legend.text = element_text(size = 12),  
        legend.title = element_text(size = 14, face = "bold") 
    )


```











